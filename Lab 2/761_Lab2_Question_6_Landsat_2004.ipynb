{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2, Question 6\n",
    "\n",
    "(6) Exercise: using an SVM model and the Landcare NZ 2024 landcover database, produce a landcover map of Great Barrier (Aotea) Island for 2025 (based off the Austral summer of 24/25).\n",
    "\n",
    "Your map should be presented at a publication quality level with all the usual map components (scale, legend, north arrow, data attribution).\n",
    "\n",
    "You will need to provide performance statistics of the model within your figure.\n",
    "\n",
    "*   Here you can access the landcover database: https://lris.scinfo.org.nz/layer/104400-lcdb-v50-land-cover-database-version-50-mainland-new-zealand/. You will need to explore for yourself how to extract this data and then upload it to colab, then how to plug it into the SVM algorithim. I have provided some starter code below.\n",
    "\n",
    "An intial workflow to get the data into the state you need it in to then use it as training data might look like:\n",
    "- Download the ZIP manually from their browser, having set your area of interest and used the 'Export' tool top right.\n",
    "- Upload it to Colab.\n",
    "- Unzip it and load with GeoPandas.\n",
    "(25 pts)\n",
    "\n",
    "\n",
    "_______________________________________________________________________________\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oTVEkaWvOjHL"
   },
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    from google.colab import userdata\n",
    "    EE_PROJECT_ID = userdata.get('EE_PROJECT_ID') \n",
    "else:\n",
    "    from dotenv import load_dotenv\n",
    "    import os\n",
    "    load_dotenv()  # take environment variables\n",
    "    EE_PROJECT_ID = os.getenv('EE_PROJECT_ID')\n",
    "\n",
    "# Set up GEE API\n",
    "import ee\n",
    "ee.Authenticate()\n",
    "ee.Initialize(project=EE_PROJECT_ID) #<- Remember to change this to your own project's name!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YIR6jwwAOs_v"
   },
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import urllib.request\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "import geemap\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Read Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.1. Load LCDB v5.0 - Land Cover Database version 5.0, Mainland, New Zealand for 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42  # Random seed for reproducibility\n",
    "\n",
    "# Correct order: [xmin, ymin, xmax, ymax]\n",
    "aoi = ee.Geometry.Rectangle([175.27, -36.36, 175.57, -36.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_clouds(image):\n",
    "    qa = image.select('QA_PIXEL')\n",
    "    # Mask dilated clouds, cirrus, cloud, and cloud shadow\n",
    "    mask = (qa.bitwiseAnd(1 << 1).eq(0)  # dilated\n",
    "            .And(qa.bitwiseAnd(1 << 2).eq(0))  # cirrus\n",
    "            .And(qa.bitwiseAnd(1 << 3).eq(0))  # cloud\n",
    "            .And(qa.bitwiseAnd(1 << 4).eq(0)))  # shadow\n",
    "    return image.updateMask(mask)\n",
    "\n",
    "# Applies scaling factors.\n",
    "def apply_scale_factors(image):\n",
    "  optical_bands = image.select('SR_B.').multiply(0.0000275).add(-0.2)\n",
    "  thermal_bands = image.select('ST_B.*').multiply(0.00341802).add(149.0)\n",
    "  return image.addBands(optical_bands, None, True).addBands(\n",
    "      thermal_bands, None, True\n",
    "  )\n",
    "\n",
    "l5 = (ee.ImageCollection('LANDSAT/LT05/C02/T1_L2')\n",
    "           .filterBounds(aoi)\n",
    "           .filter(ee.Filter.lt('CLOUD_COVER', 10)))\n",
    "\n",
    "l5_2004 = (l5\n",
    "           .filterDate('2004-01-01', '2004-12-31')\n",
    "           .map(mask_clouds)\n",
    "           .map(apply_scale_factors)\n",
    "           .median()\n",
    "           .clip(aoi))\n",
    "\n",
    "viz_rgb_params = {\n",
    "    'bands': ['SR_B3', 'SR_B2', 'SR_B1'],\n",
    "    'min': 0.0,\n",
    "    'max': 0.3,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.x Preparation classification data\n",
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import zipfile\n",
    "# import geopandas as gpd\n",
    "\n",
    "# # Upload the ZIP manually using the Colab UI\n",
    "# from google.colab import files\n",
    "# uploaded = files.upload()  # <- Expects a ZIP\n",
    "\n",
    "# Unzip\n",
    "# with zipfile.ZipFile(\"LCDB_v5.zip\", 'r') as zip_ref: #<- Check file names\n",
    "#     zip_ref.extractall(\"lcdb\")\n",
    "\n",
    "# Read shapefile\n",
    "gdf = gpd.read_file(\"../dataset/lris-lcdb-v50-land-cover-great-barrier-SHP/lcdb-v50-land-cover-database-version-50-mainland-new-zealand.shp\")\n",
    "df = gdf[['Name_2018', 'Class_2018', 'geometry', 'LCDB_UID']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf['EditDate'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### => Should use 2004 image => Landsat-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Have a quick look at class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_2018_lcdb = geemap.geopandas_to_ee(df[['Class_2018', 'geometry']])\n",
    "\n",
    "# rasterizes the data\n",
    "class_2018_lcdb_image = class_2018_lcdb.reduceToImage(\n",
    "    properties=['Class_2018'],\n",
    "    reducer=ee.Reducer.first()\n",
    ").rename('Class_2018').clip(aoi).toInt()\n",
    "\n",
    "pixel_counts = l5_2004.updateMask(class_2018_lcdb_image).addBands(class_2018_lcdb_image).select('Class_2018').reduceRegion(\n",
    "    reducer=ee.Reducer.frequencyHistogram(),\n",
    "    geometry=aoi,\n",
    "    scale=30,  # The spatial resolution of your imagery, in meters.\n",
    "    maxPixels=1e9 # A large number to ensure all pixels are counted.\n",
    ")\n",
    "\n",
    "display(pixel_counts.getInfo())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> The data is imbalance, and only a part (22/36 classes) of classes from original dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.x Merge classes\n",
    "- Reduce model complexity. SVM is natively aim to solve binary classification\n",
    "- Reduce imbalancing of data => better performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_classes = {\n",
    "    52: 1, # (Scrub) Manuka and/or Kanuka\t                198,722\n",
    "    33: 1, # (Scrub) Manuka and/or Kanuka                   196\n",
    "    54: 1, # (Scrub) Broadleaved Indigenous Hardwoods\t    64,287\n",
    "    51: 1, # (Scrub) Gorse and/or Broom                     758\n",
    "    69: 2, # (Forest) Indigenous Forest\t                    89,235\n",
    "    71: 2, # (Forest) Exotic Forest                         2,203\n",
    "    40: 3, # (Grassland) High Producing Exotic Grassland    22,912\n",
    "    41: 3, # (Grassland) Low Producing Grassland            5,075\n",
    "    70: 4, # (Mangrove) Mangrove                            1,756\n",
    "    10: 5, # (Bare) Sand or Gravel                          12,897\n",
    "    16: 5, # (Bare) Gravel or Rock                          1,206\n",
    "    64: 5, # (Bare) Forest - Harvested                      129\n",
    "    12: 5, # (Bare) Landslide                               6\n",
    "    45: 6, # (Herbaceous) Herbaceous Freshwater Vegetation  4,403\n",
    "    46: 6, # (Herbaceous) Herbaceous Saline Vegetation      2,508\n",
    "    22: 7, # (Water) Estuarine Open Water                   1,243\n",
    "    21: 7, # (Water) River                                  100\n",
    "    20: 7, # (Water) Lake or Pond                           22\n",
    "    1: 8,  # (Urban) Built-up Area (settlement)             1,192\n",
    "    2: 8,  # (Urban) Parkland/Open Space                    318\n",
    "    5: 8,  # (Urban) Transport Infrastructure               63\n",
    "    6: 9,  # (Other) Surface Mine or Dump                   32\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_range = list(range(1, 10))  # Creates a list [1, 2, ..., 9]\n",
    "\n",
    "class_property = 'class_mapped_2018'\n",
    "# Map classes to new values, default to 0 if not found\n",
    "df[class_property] = df['Class_2018'].map(lambda x: mapped_classes.get(x, 0))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.x Feature enhancement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l5_bands = ['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B7']\n",
    "# l8_bands = ['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6', 'SR_B7']\n",
    "\n",
    "# bands = l8_bands\n",
    "bands = l5_bands + ['NDVI', 'NDWI', 'EVI', 'SAVI', 'NBR']\n",
    "\n",
    "# Calculate vegetation indices\n",
    "def add_vegetation_indices(image):\n",
    "    # NDVI: (NIR - Red) / (NIR + Red)\n",
    "    ndvi = image.normalizedDifference(['SR_B4', 'SR_B3']).rename('NDVI')\n",
    "    # NDWI: (Green - NIR) / (Green + NIR)\n",
    "    ndwi = image.normalizedDifference(['SR_B2', 'SR_B4']).rename('NDWI')\n",
    "    evi = image.expression(\n",
    "        '2.5 * ((NIR - RED) / (NIR + 6 * RED - 7.5 * BLUE + 1))', {\n",
    "        'NIR': image.select('SR_B4'),\n",
    "        'RED': image.select('SR_B3'),\n",
    "        'BLUE': image.select('SR_B1')\n",
    "    }).rename('EVI')\n",
    "    savi = image.expression(\n",
    "        '1.5 * ((NIR - RED) / (NIR + RED + 0.5))', {\n",
    "        'NIR': image.select('SR_B4'),\n",
    "        'RED': image.select('SR_B3')\n",
    "    }).rename('SAVI')\n",
    "    # NBR: (NIR - SWIR2) / (NIR + SWIR2)\n",
    "    nbr = image.normalizedDifference(['SR_B4', 'SR_B7']).rename('NBR')\n",
    "\n",
    "    return image.addBands([ndvi, ndwi, evi, savi, nbr])\n",
    "\n",
    "lcdb = geemap.geopandas_to_ee(df[[class_property, 'geometry']])\n",
    "\n",
    "# rasterizes the data\n",
    "lcdb_image = lcdb.reduceToImage(\n",
    "    properties=[class_property],\n",
    "    reducer=ee.Reducer.first()\n",
    ").rename(class_property).clip(aoi).toInt()\n",
    "\n",
    "class_2018_lcdb_image = geemap.geopandas_to_ee(df[['Class_2018', 'geometry']]) \\\n",
    "    .reduceToImage(\n",
    "        properties=['Class_2018'],\n",
    "        reducer=ee.Reducer.first()\n",
    "    ).rename('Class_2018').clip(aoi).toInt()\n",
    "\n",
    "# Apply scale factors so SR bands are in reflectance (approx 0-1)\n",
    "# `lcdb` only covers land. Need to mark unlabled areas in `l5_2004`.\n",
    "# l5_2004_lc = apply_scale_factors(l5_2004).updateMask(lcdb_image)\n",
    "l5_2004_lc = l5_2004.updateMask(lcdb_image)\n",
    "\n",
    "# Combine the bands of interest with the land cover data\n",
    "# The `class_property` band will be used as our label\n",
    "training_image = add_vegetation_indices(l5_2004_lc.addBands(lcdb_image))\n",
    "#     .select(bands + [class_property])\n",
    "    \n",
    "# training_image = l8_2018_lc.addBands(lcdb_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Map = geemap.Map(center=[-36.1830, 175.3785], zoom=11)\n",
    "Map.addLayer(aoi, {}, 'AOI')\n",
    "Map.add_layer(\n",
    "    class_2018_lcdb_image.select('Class_2018').randomVisualizer(), {}, 'LCDB v5.0'\n",
    ")\n",
    "Map.add_layer(\n",
    "    l5_2004, viz_rgb_params, 'l5 2004'\n",
    ")\n",
    "Map.add_layer(\n",
    "    training_image, viz_rgb_params, 'L5 2004 (Land Cover)'\n",
    ")\n",
    "Map.add_layer(\n",
    "    training_image.select(class_property).randomVisualizer(), {}, 'Groupped - LCDB v5.0'\n",
    ")\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sample the image to create training data\n",
    "# # This will create a FeatureCollection where each feature has the pixel values \n",
    "# # for the bands and the corresponding land cover class.\n",
    "training_data = training_image.select(bands + [class_property]).stratifiedSample(\n",
    "    classBand=class_property,\n",
    "    region=aoi,\n",
    "    scale=30,  # The spatial resolution to sample at\n",
    "    numPoints=500,  # The number of data points for each class\n",
    "    seed=seed,  # Random seed for reproducibility\n",
    "    geometries=True,  # Include the geometry of each sampled pixel\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_10 = training_data.limit(10).getInfo()\n",
    "\n",
    "print('\\nFirst 10 training samples:')\n",
    "for i, feature in enumerate(first_10['features']):\n",
    "    props = feature['properties']\n",
    "    print(f\"Sample {i+1}: Class={props[class_property]}, SR_B2={props['SR_B2']}, SR_B3={props['SR_B3']}, SR_B4={props['SR_B4']}, SR_B7={props['SR_B7']}\")\n",
    "\n",
    "# Count number of samples per class (server-side)\n",
    "class_counts = training_data.reduceColumns(\n",
    "    reducer=ee.Reducer.frequencyHistogram(),\n",
    "    selectors=[class_property])\n",
    "\n",
    "print('\\nClass distribution in sample:')\n",
    "print(class_counts.getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add random column\n",
    "training_data = training_data.randomColumn('random')\n",
    "\n",
    "# Split\n",
    "train_set = training_data.filter(ee.Filter.lt('random', 0.8))\n",
    "# valid_set = training_data.filter(ee.Filter.And(ee.Filter.gte('random', 0.7), ee.Filter.lt('random', 0.9)))\n",
    "test_set = training_data.filter(ee.Filter.gte('random', 0.8))\n",
    "\n",
    "# train_set = training_data.filter(ee.Filter.lt('random', 0.7))\n",
    "# valid_set = training_data.filter(ee.Filter.And(ee.Filter.gte('random', 0.7), ee.Filter.lt('random', 0.9)))\n",
    "# test_set = training_data.filter(ee.Filter.gte('random', 0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = ee.Classifier.libsvm(kernelType='RBF', gamma=8, cost=1_000).train(\n",
    "    features=train_set,\n",
    "    classProperty=class_property,\n",
    "    inputProperties=bands\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a confusion matrix and overall accuracy for the training sample.\n",
    "train_accuracy = svm.confusionMatrix()\n",
    "display('Training overall accuracy', train_accuracy.accuracy().getInfo())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test to find good combination of `gamma` and `cost`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gammas = [0.5, 1, 2, 4, 8, 16, 32, 64]\n",
    "# costs = [10, 100, 200, 500, 1000, 30000, 50000, 100000]\n",
    "\n",
    "# for gamma, cost in zip(gammas, costs):\n",
    "#     svm = ee.Classifier.libsvm(kernelType='RBF', gamma=gamma, cost=cost).train(\n",
    "#         features=train_set,\n",
    "#         classProperty=class_property,\n",
    "#         inputProperties=bands\n",
    "#     )\n",
    "    \n",
    "#     print(f'Gamma: {gamma}, Cost: {cost}')\n",
    "    \n",
    "#     train_accuracy = svm.confusionMatrix()\n",
    "#     print(f'Training overall accuracy: {train_accuracy.accuracy().getInfo()}')\n",
    "\n",
    "#     # Classify the test set\n",
    "#     test_classified = test_set.classify(svm)\n",
    "\n",
    "#     # Get the confusion matrix\n",
    "#     confusion_matrix = test_classified.errorMatrix(class_property, 'classification')\n",
    "\n",
    "#     # Print the confusion matrix and accuracy\n",
    "    \n",
    "#     print('Overall Accuracy:', confusion_matrix.accuracy().getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TESTING\n",
    "\n",
    "# Austral summer of 24/25\n",
    "l5_2025_lc = (l5\n",
    "           .filterDate('2024-09-01', '2025-07-31')\n",
    "           .map(mask_clouds)\n",
    "           .median()\n",
    "           .updateMask(lcdb_image)\n",
    "           .clip(aoi))\n",
    "\n",
    "# Apply scale factors for consistency with training\n",
    "# dl8_2025 = apply_scale_factors(l8_2025)\n",
    "\n",
    "# l5_2025_classified = dl5_2025.updateMask(lcdb_image).classify(svm).select(l5_bands)\n",
    "\n",
    "# l5_2018_classified = l5_2018_lc.classify(svm).select(l5_bands)\n",
    "\n",
    "# Add vegetation indices to l5_2018_lc before classification\n",
    "# l5_2018_lc_with_indices = add_vegetation_indices(l5_2018_lc)\n",
    "l5_2004_classified = add_vegetation_indices(l5_2004_lc).classify(svm)\n",
    "l5_2025_classified = add_vegetation_indices(l5_2025_lc).classify(svm)\n",
    "\n",
    "t_map = geemap.Map()\n",
    "t_map.centerObject(aoi, 11)\n",
    "# t_map.addLayer(l5_2025_lc, viz_rgb_params, '2025 RGB')\n",
    "# t_map.addLayer(l5_2025_classified.randomVisualizer(), {}, '2025 Classified')\n",
    "t_map.addLayer(l5_2004_lc, viz_rgb_params, '2004 RGB')\n",
    "t_map.addLayer(l5_2004_classified.randomVisualizer(), {}, '2004 Classified')\n",
    "t_map.addLayer(lcdb_image.randomVisualizer(), {} ,'LCDB v5.0')\n",
    "\n",
    "t_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display('Results of trained classifier', svm.explain())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a confusion matrix and overall accuracy for the training sample.\n",
    "train_accuracy = svm.confusionMatrix()\n",
    "display('Training overall accuracy', train_accuracy.accuracy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_classified = test_set.classify(svm)\n",
    "\n",
    "# Function to export data for confusion matrix\n",
    "def fc_to_lists(fc, classProp, predProp):\n",
    "    values = fc.aggregate_array(classProp).getInfo()\n",
    "    preds = fc.aggregate_array(predProp).getInfo()\n",
    "    return values, preds\n",
    "\n",
    "# Get predicted vs actual from test set\n",
    "y_true, y_pred = fc_to_lists(test_classified, class_property, 'classification')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred, labels=class_range)\n",
    "report = classification_report(y_true, y_pred, labels=class_range, target_names=[str(l) for l in class_range], output_dict=True)\n",
    "\n",
    "# Pretty-print\n",
    "print(\"Confusion Matrix:\")\n",
    "print(pd.DataFrame(cm, index=[f\"Actual {l}\" for l in class_range],\n",
    "                       columns=[f\"Pred {l}\" for l in class_range]))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate test performance\n",
    "test_matrix = test_classified.errorMatrix(class_property, 'classification')\n",
    "# print(\"Confusion Matrix:\")\n",
    "# print(pd.DataFrame(test_matrix.getInfo(), index=[f\"Actual {l}\" for l in classes_2018],\n",
    "#                        columns=[f\"Pred {l}\" for l in classes_2018]))\n",
    "# print(\"\\nClassification Report:\")\n",
    "# print(report)\n",
    "\n",
    "# print('Error matrix:')\n",
    "# print(test_matrix.getInfo())\n",
    "\n",
    "# Compute accuracy metrics from the error matrix.\n",
    "print('Overall accuracy:', test_matrix.accuracy().getInfo())\n",
    "# print('Consumer\\'s accuracy:')\n",
    "# print(test_matrix.consumersAccuracy().getInfo())\n",
    "# print('Producer\\'s accuracy:')\n",
    "# print(test_matrix.producersAccuracy().getInfo())\n",
    "print('Kappa:', test_matrix.kappa().getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Austral summer of 24/25\n",
    "l8_2025_lc = (ee.ImageCollection(\"LANDSAT/LC08/C02/T1_L2\")\n",
    "           .filterBounds(aoi)\n",
    "           .filter(ee.Filter.lt('CLOUD_COVER', 10))\n",
    "           .filterDate('2024-09-01', '2025-07-31')\n",
    "           .map(mask_clouds)\n",
    "           .map(apply_scale_factors)\n",
    "           .median()\n",
    "           .updateMask(lcdb_image)\n",
    "           .clip(aoi)\n",
    "           .select(['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6', 'SR_B7']))\n",
    "\n",
    "l8_2025_lc = l8_2025_lc.rename(['SR_B0'] + l5_bands)\n",
    "\n",
    "l8_2025_classified = add_vegetation_indices(l8_2025_lc).classify(svm)\n",
    "l5_2004_classified = add_vegetation_indices(l5_2004_lc).classify(svm)\n",
    "\n",
    "m = geemap.Map()\n",
    "m.centerObject(aoi, 11)\n",
    "m.addLayer(l5_2004_lc, viz_rgb_params, '2004 RGB')\n",
    "m.addLayer(l5_2004_classified.randomVisualizer(), {}, '2004 Classified')\n",
    "m.addLayer(l8_2025_lc, viz_rgb_params, '2025 RGB')\n",
    "m.addLayer(l8_2025_classified.randomVisualizer(), {}, '2025 Classified')\n",
    "m.addLayer(lcdb_image.randomVisualizer(), {} ,'LCDB v5.0')\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classNames = [\n",
    "    'Scrub',\n",
    "    'Forest',\n",
    "    'Grassland',\n",
    "    'Mangrove',\n",
    "    'Bare',\n",
    "    'Herbaceous',\n",
    "    'Water',\n",
    "    'Urban',\n",
    "    'Other',\n",
    "]\n",
    "\n",
    "classPalette = [\n",
    "    '006400',\n",
    "    'ffbb22',\n",
    "    'ffff4c',\n",
    "    'f096ff',\n",
    "    'fa0000',\n",
    "    'b4b4b4',\n",
    "    '0064c8',\n",
    "    '0096a0',\n",
    "    'fae6a0',\n",
    "]\n",
    "\n",
    "vis_params = {\n",
    "    'min': 1,\n",
    "    'max': 9,\n",
    "    'palette': classPalette\n",
    "}\n",
    "\n",
    "thumb_params = vis_params | {\n",
    "    'dimensions': 512,\n",
    "    'region': aoi,\n",
    "    'format': 'png',\n",
    "}\n",
    "\n",
    "coords = aoi.coordinates().getInfo()[0]\n",
    "lons = [pt[0] for pt in coords]\n",
    "lats = [pt[1] for pt in coords]\n",
    "xmin, xmax, ymin, ymax = min(lons), max(lons), min(lats), max(lats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.1. Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classified Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classified_imgs = []\n",
    "\n",
    "for classified in [l5_2004_classified, l8_2025_classified]:\n",
    "    # Download the image for the year\n",
    "    url = classified.getThumbURL(thumb_params)\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".png\") as f:\n",
    "        urllib.request.urlretrieve(url, f.name)\n",
    "        img = mpimg.imread(f.name)\n",
    "        classified_imgs.append(img)\n",
    "    display(Image(url=url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ground Truth Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "based_url = lcdb_image.getThumbURL(thumb_params)\n",
    "with tempfile.NamedTemporaryFile(suffix=\".png\") as f:\n",
    "    urllib.request.urlretrieve(based_url, f.name)\n",
    "    based_img = mpimg.imread(f.name)\n",
    "display(Image(url=based_url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.3. Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = ['accuracy', 'macro avg', 'weighted avg']\n",
    "cols = ['precision', 'recall', 'f1-score']\n",
    "df_report = pd.DataFrame(report)[rows]\n",
    "\n",
    "df_plot = df_report.transpose()[cols]\n",
    "df_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.4. Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = ['2025', '2004']\n",
    "landsats = ['Landsats-8', 'Landsats-5']\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# layout = [['A', 'A', 'B', 'B'],\n",
    "#           ['C', 'C', 'D', 'D'],\n",
    "#           ['E', 'E', 'E', 'E']]\n",
    "# fig, axes = plt.subplot_mosaic(layout, figsize=(12, 10), height_ratios=[5,5,1])\n",
    "\n",
    "# layout = [['A', 'A', 'A', 'A'],\n",
    "#           ['B', 'B', 'C', 'C'],\n",
    "#           ['D', 'D', 'D', 'D'],\n",
    "#           ['E', 'E', 'E', 'E']]\n",
    "# fig, axes = plt.subplot_mosaic(layout, figsize=(12, 10), height_ratios=[10, 5, 1, 1])\n",
    "\n",
    "layout = [['A', 'A', 'B', 'B'],\n",
    "          ['A', 'A', 'C', 'C'],\n",
    "          ['D', 'D', 'E', 'E']]\n",
    "fig, axes = plt.subplot_mosaic(layout, figsize=(10, 10), height_ratios=[5, 5, 3])\n",
    "\n",
    "class_axe = [axes['A'], axes['B']]\n",
    "based_axe = axes['C']\n",
    "ledgend_axe = axes['D']\n",
    "report_axe = axes['E']\n",
    "\n",
    "colors = ['#' + v for v in classPalette]\n",
    "# Create the custom colormap\n",
    "cmap = mcolors.ListedColormap(colors)\n",
    "\n",
    "for idx, axe in enumerate(class_axe):\n",
    "    axe.set_title(f'Classified image of {years[idx]} ({landsats[idx]})')\n",
    "    axe.imshow(classified_imgs[idx], extent=[xmin, xmax, ymin, ymax], cmap=cmap, vmin=1, vmax=10)\n",
    "    axe.axis('off')  # Hide the axes\n",
    "\n",
    "# LEDGEND\n",
    "# Loop through the labels and colors to create squares and text\n",
    "for i, (color, class_name) in enumerate(zip(classPalette, classNames)):\n",
    "    spacing = 0.14\n",
    "    # Create a colored square patch\n",
    "    y_position = (10 - i) * spacing\n",
    "    rect = patches.Rectangle((0.1, y_position), 0.07, 0.1, facecolor=f'#{color}', edgecolor='none')\n",
    "    ledgend_axe.add_patch(rect)\n",
    "\n",
    "    # Add the text label beside the square\n",
    "    # The y-coordinate is also based on y_position\n",
    "    ledgend_axe.text(0.2, y_position + 0.05, class_name, va='center', ha='left', fontsize=9)\n",
    "\n",
    "    ledgend_axe.set_xlim(0, 1)\n",
    "    ledgend_axe.set_ylim(0, 1.5)\n",
    "    ledgend_axe.axis('off')\n",
    "ledgend_axe.set_title('Classes Colors')\n",
    "    \n",
    "# Based image\n",
    "based_axe.imshow(based_img, extent=[xmin, xmax, ymin, ymax], cmap=cmap, vmin=10, vmax=100)\n",
    "based_axe.set_title('LCDB v5.0 - Land Cover Database version 5.0')\n",
    "based_axe.axis('off')  # Hide the axes\n",
    "\n",
    "# REPORT TABLE\n",
    "report_axe.axis('off') # Hide the axes\n",
    "report_axe.set_title('The accuracy averages of the SVM classifier.')\n",
    "\n",
    "# formant float values in the table\n",
    "df_plot = df_plot.applymap(lambda x: f'{x:.4f}' if isinstance(x, (int, float)) else x)\n",
    "\n",
    "# Create the table\n",
    "table = report_axe.table(\n",
    "    cellText=df_plot.values,\n",
    "    colLabels=df_plot.columns.str.capitalize(),\n",
    "    rowLabels=df_plot.index.str.capitalize(),\n",
    "    loc='best',\n",
    "    cellLoc='center'\n",
    ")\n",
    "\n",
    "table.scale(0.8, 0.8)  # Adjust table size\n",
    "\n",
    "# Make headers bold\n",
    "for (i, j), cell in table.get_celld().items():\n",
    "    if i == 0 or j == -1: # Row 0 is the header, column -1 is the index\n",
    "        cell.set_text_props(weight='bold', color='w')\n",
    "        cell.set_facecolor('teal') # Header color\n",
    "\n",
    "caption = '''\n",
    "Figure x: Land cover Classification map of Great Barrier (Aotea) Island for the Austral summer of 24/25\\n Using SVM trainned on Landsat 5 (2004) Data and Land Cover Database version 5.0.\n",
    "'''\n",
    "plt.figtext(0.5, -0.03, caption, wrap=True, horizontalalignment='center', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show() "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "geo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
